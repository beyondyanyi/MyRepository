1.Map负责分

即把复杂的任务分解为若干个“简单的任务”来处理。
“简单的任务”包含三层含义：

一是数据或计算的规模相对原任务要大大缩小；
二是就近计算原则，即任务会分配到存放着所需数据的节点上进行计算；
三是这些小任务可以并行计算，彼此间几乎没有依赖关系

2.Reduce负责对map阶段的结果进行汇总

至于需要多少个Reducer，用户可以根据具体问题，通过在mapred-site.xml配置文件里设置参数mapred.reduce.tasks的值，缺省值为1




一个比较形象的语言解释MapReduce：　　

我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。

现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。




MapReduce的整个工作过程如上图所示，它包含如下4个独立的实体：

实体一： 客户端，用来提交MapReduce作业
实体二： JobTracker,用来协调作业的运行

			JobTracker负责调度构成一个作业的所有任务，这些任务分布在不同的TaskTracker上（由上图的JobTracker可以看到2 assign map 和 3 assign reduce）。你可以将其理解为公司的项目经理，项目经理接受项目需求，并划分具体的任务给下面的开发工程师。
			
实体三： TaskTracker,用来处理作业划分后的任务

			TaskTracker负责执行由JobTracker指派的任务，这里我们就可以将其理解为开发工程师，完成项目经理安排的开发任务即可。

实体四： HDFS,用来在其他实体间共享作业文件





MapReduce框架运转在<key,value>键值对上，也就是说，框架把作业的输入看成是一组<key,value>键值对，同样也产生一组<key,value>键值对作为作业的输出，这两组键值对有可能是不同的。

　　一个MapReduce作业的输入和输出类型如下图所示：可以看出在整个流程中，会有三组<key,value>键值对类型的存在。